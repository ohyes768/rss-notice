"""
RSSæ‹‰å–æ¨¡å—
è´Ÿè´£è§£æRSSæºå¹¶æå–æ–‡ç« ä¿¡æ¯
"""
import feedparser
import hashlib
import logging
from typing import List, Dict
from datetime import datetime

from storage import Storage

logger = logging.getLogger(__name__)


class RSSFetcher:
    """RSSè®¢é˜…æºæ‹‰å–å™¨"""

    def __init__(self, storage: Storage):
        self.storage = storage

    def _generate_article_id(self, article_link: str) -> str:
        """ç”Ÿæˆæ–‡ç« å”¯ä¸€ID(MD5)"""
        return hashlib.md5(article_link.encode('utf-8')).hexdigest()

    def _generate_markdown(self, title: str, link: str, published: datetime, feed_title: str) -> str:
        """ç”Ÿæˆæ–‡ç« çš„Markdownæ ¼å¼ä¿¡æ¯"""
        published_time = published.strftime('%Y-%m-%d %H:%M') if published else 'æœªçŸ¥'

        markdown = f"""ğŸ“° å…¬ä¼—å·ã€Œ{feed_title}ã€ä»Šæ—¥æ›´æ–°

### {title}

ğŸ“… å‘å¸ƒï¼š{published_time}
ğŸ”— é“¾æ¥ï¼š{link}

---
"""
        return markdown

    def fetch_new_articles(self, rss_url: str, tag: str) -> Dict:
        """æ‹‰å–æ–°æ–‡ç« ï¼ˆè¿‡æ»¤å·²å¤„ç†çš„ï¼‰"""
        logger.info(f"å¼€å§‹æ‹‰å–RSS: {rss_url} (tag: {tag})")

        try:
            # è§£æRSS
            feed = feedparser.parse(rss_url)

            if feed.bozo:
                logger.warning(f"RSSè§£æå¯èƒ½æœ‰è¯¯: {feed.bozo_exception}")

            feed_title = feed.feed.get('title', 'Unknown RSS')

            # è§£ææ–‡ç« 
            all_articles = []
            for entry in feed.entries:
                try:
                    article_id = self._generate_article_id(entry.link)

                    # è§£æå‘å¸ƒæ—¶é—´
                    published = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published = datetime(*entry.published_parsed[:6])

                    # ç”ŸæˆMarkdown
                    markdown = self._generate_markdown(
                        title=entry.get('title', 'Untitled'),
                        link=entry.link,
                        published=published,
                        feed_title=feed_title
                    )

                    article = {
                        'id': article_id,
                        'title': entry.get('title', 'Untitled'),
                        'link': entry.link,
                        'published': published.isoformat() if published else None,
                        'author': entry.get('author'),
                        'markdown': markdown
                    }
                    all_articles.append(article)
                except Exception as e:
                    logger.warning(f"è§£ææ–‡ç« å¤±è´¥: {e}, è·³è¿‡")
                    continue

            logger.info(f"è§£æåˆ° {len(all_articles)} ç¯‡æ–‡ç« ")

            # è¿‡æ»¤æ–°æ–‡ç« ï¼ˆæŒ‰tagï¼‰
            new_articles = [
                article for article in all_articles
                if not self.storage.is_article_processed(article['id'], tag)
            ]

            logger.info(f"å…¶ä¸­ {len(new_articles)} ç¯‡ä¸ºæ–°æ–‡ç«  (tag: {tag})")

            return {
                'tag': tag,
                'feed_title': feed_title,
                'new_articles': new_articles
            }

        except Exception as e:
            logger.error(f"æ‹‰å–RSSå¤±è´¥: {e}", exc_info=True)
            raise
