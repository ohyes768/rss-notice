# RSS监控系统实现方案（FastAPI + API Gateway）

## 项目概述
实现一个符合API Gateway规范的FastAPI微服务，提供RSS订阅监控功能。n8n通过API Gateway调用服务接口获取新文章，然后发送到钉钉。

## 技术栈
- Python 3.11+
- uv (包管理)
- FastAPI (Web框架)
- uvicorn (ASGI服务器)
- feedparser (RSS解析)
- SQLite (持久化存储)
- Pydantic (数据验证)

## 项目目录结构
```
rss-notice/
├── backend/
│   └── rss_notice_service/     # 服务代码
│       ├── main.py             # FastAPI应用入口
│       ├── models.py           # 数据模型定义
│       ├── rss_fetcher.py      # RSS拉取模块
│       ├── storage.py          # SQLite持久化存储
│       ├── config.py           # 配置管理
│       ├── logger.py           # 日志配置
│       ├── Dockerfile          # Docker镜像构建
│       └── requirements.txt    # 依赖列表
├── docker/
│   └── docker-compose.yml      # Docker Compose配置
├── data/                       # 数据存储目录
│   └── .gitkeep
└── README.md
```

## 核心依赖
```txt
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
feedparser>=6.0.10
pydantic>=2.5.0
requests>=2.31.0
python-dotenv>=1.0.0
```

## API设计

### 1. 健康检查（必需）
```
GET /health
```
响应：
```json
{
  "status": "healthy",
  "service": "rss-notice",
  "timestamp": "2026-02-09T12:00:00Z"
}
```

### 2. 检查新文章（核心接口）
```
GET /api/rss/check
```
响应：
```json
{
  "feed_title": "今天看啥RSS",
  "feed_url": "http://rss.jintiankansha.me/...",
  "check_time": "2026-02-09T02:45:00",
  "new_count": 3,
  "articles": [
    {
      "id": "abc123...",
      "title": "文章标题",
      "link": "https://...",
      "published": "2026-02-08T10:30:00",
      "author": "作者名",
      "summary": "摘要...",
      "content": null
    }
  ]
}
```

### 3. 手动刷新（可选）
```
POST /api/rss/refresh
```
强制重新检查RSS源，忽略缓存。

## 实现步骤

### 步骤1: 创建项目目录结构
```bash
cd F:\github\person_project\rss-notice
mkdir -p backend/rss_notice_service
mkdir -p docker
mkdir -p data
```

### 步骤2: 初始化uv项目
```bash
cd backend/rss_notice_service
uv init --no-readme
```

### 步骤3: 安装依赖
```bash
uv add fastapi uvicorn[standard] feedparser pydantic requests python-dotenv
```

### 步骤4: 实现核心模块

#### 1. **models.py** - 数据模型定义
```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import List, Optional

class Article(BaseModel):
    """文章数据模型"""
    id: str = Field(..., description="文章唯一标识(MD5)")
    title: str = Field(..., description="文章标题")
    link: str = Field(..., description="文章链接")
    published: Optional[datetime] = Field(None, description="发布时间")
    author: Optional[str] = Field(None, description="作者")
    summary: Optional[str] = Field(None, description="摘要")
    content: Optional[str] = Field(None, description="正文内容")

    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

class RSSCheckResponse(BaseModel):
    """RSS检查响应"""
    feed_title: str = Field(..., description="订阅源标题")
    feed_url: str = Field(..., description="订阅源URL")
    check_time: datetime = Field(default_factory=datetime.now, description="检查时间")
    new_count: int = Field(..., description="新增文章数量")
    articles: List[Article] = Field(..., description="新增文章列表")

    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

class HealthResponse(BaseModel):
    """健康检查响应"""
    status: str = Field(..., description="健康状态")
    service: str = Field(..., description="服务名称")
    timestamp: datetime = Field(default_factory=datetime.now, description="时间戳")
```

#### 2. **storage.py** - SQLite持久化存储
```python
import sqlite3
import hashlib
from pathlib import Path
from typing import Set
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class Storage:
    """SQLite持久化存储"""

    def __init__(self, db_path: str = "data/rss_notice.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()

    def _init_db(self):
        """初始化数据库表"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS articles (
                    id TEXT PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT NOT NULL,
                    published TEXT,
                    author TEXT,
                    summary TEXT,
                    created_at TEXT NOT NULL
                )
            """)
            conn.commit()
            logger.info(f"数据库初始化完成: {self.db_path}")

    def is_article_processed(self, article_id: str) -> bool:
        """检查文章是否已处理"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                "SELECT 1 FROM articles WHERE id = ? LIMIT 1",
                (article_id,)
            )
            return cursor.fetchone() is not None

    def save_articles(self, articles: list) -> int:
        """保存文章到数据库，返回保存数量"""
        saved_count = 0
        now = datetime.now().isoformat()

        with sqlite3.connect(self.db_path) as conn:
            for article in articles:
                try:
                    conn.execute(
                        """
                        INSERT INTO articles
                        (id, title, link, published, author, summary, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                        """,
                        (
                            article['id'],
                            article['title'],
                            article['link'],
                            article.get('published'),
                            article.get('author'),
                            article.get('summary'),
                            now
                        )
                    )
                    saved_count += 1
                except sqlite3.IntegrityError:
                    pass  # 文章已存在
            conn.commit()
            logger.info(f"保存了 {saved_count} 篇新文章")
            return saved_count
```

#### 3. **rss_fetcher.py** - RSS拉取模块
```python
import feedparser
import hashlib
import logging
from typing import List, Dict
from datetime import datetime

from src.storage import Storage

logger = logging.getLogger(__name__)

class RSSFetcher:
    """RSS订阅源拉取器"""

    def __init__(self, storage: Storage):
        self.storage = storage

    def _generate_article_id(self, article_link: str) -> str:
        """生成文章唯一ID(MD5)"""
        return hashlib.md5(article_link.encode('utf-8')).hexdigest()

    def fetch_new_articles(self, rss_url: str) -> Dict:
        """拉取新文章（过滤已处理的）"""
        logger.info(f"开始拉取RSS: {rss_url}")

        try:
            # 解析RSS
            feed = feedparser.parse(rss_url)

            if feed.bozo:
                logger.warning(f"RSS解析可能有误: {feed.bozo_exception}")

            feed_title = feed.feed.get('title', 'Unknown RSS')

            # 解析文章
            all_articles = []
            for entry in feed.entries:
                try:
                    article_id = self._generate_article_id(entry.link)

                    # 解析发布时间
                    published = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        published = datetime(*entry.published_parsed[:6])

                    article = {
                        'id': article_id,
                        'title': entry.get('title', 'Untitled'),
                        'link': entry.link,
                        'published': published.isoformat() if published else None,
                        'author': entry.get('author'),
                        'summary': entry.get('summary'),
                        'content': entry.get('content', [{}])[0].get('value') if hasattr(entry, 'content') else None
                    }
                    all_articles.append(article)
                except Exception as e:
                    logger.warning(f"解析文章失败: {e}, 跳过")
                    continue

            logger.info(f"解析到 {len(all_articles)} 篇文章")

            # 过滤新文章
            new_articles = [
                article for article in all_articles
                if not self.storage.is_article_processed(article['id'])
            ]

            logger.info(f"其中 {len(new_articles)} 篇为新文章")

            return {
                'feed_title': feed_title,
                'new_articles': new_articles
            }

        except Exception as e:
            logger.error(f"拉取RSS失败: {e}", exc_info=True)
            raise
```

#### 4. **config.py** - 配置管理
```python
import os
from pathlib import Path
from dotenv import load_dotenv

class Config:
    """配置管理器"""

    def __init__(self):
        env_path = Path(__file__).parent / ".env"
        load_dotenv(env_path)

    @property
    def rss_url(self) -> str:
        return os.getenv("RSS_URL", "")

    @property
    def db_path(self) -> str:
        return os.getenv("DB_PATH", "data/rss_notice.db")

    @property
    def log_level(self) -> str:
        return os.getenv("LOG_LEVEL", "INFO")
```

#### 5. **logger.py** - 日志配置
```python
import logging
import sys

def setup_logger(log_level: str = "INFO"):
    """配置日志系统"""
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, log_level))

    # 清除已有处理器
    logger.handlers.clear()

    # 日志格式
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # 控制台处理器（stdout，Docker标准）
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    return logger
```

#### 6. **main.py** - FastAPI应用入口
```python
from fastapi import FastAPI, HTTPException
from datetime import datetime

from config import Config
from storage import Storage
from rss_fetcher import RSSFetcher
from logger import setup_logger
from models import HealthResponse, RSSCheckResponse, Article

# 初始化
setup_logger()
config = Config()
storage = Storage(config.db_path)
fetcher = RSSFetcher(storage)

app = FastAPI(
    title="RSS Notice Service",
    description="RSS订阅监控服务",
    version="1.0.0"
)

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """健康检查端点（必需）"""
    return HealthResponse(
        status="healthy",
        service="rss-notice"
    )

@app.get("/api/rss/check", response_model=RSSCheckResponse)
async def check_new_articles():
    """
    检查新文章
    由n8n通过API Gateway调用
    """
    try:
        if not config.rss_url:
            raise HTTPException(status_code=500, detail="RSS_URL未配置")

        # 拉取新文章
        result = fetcher.fetch_new_articles(config.rss_url)
        new_articles = result['new_articles']

        # 保存到数据库
        storage.save_articles(new_articles)

        # 转换为Article模型
        articles = [Article(**article) for article in new_articles]

        # 构造响应
        response = RSSCheckResponse(
            feed_title=result['feed_title'],
            feed_url=config.rss_url,
            new_count=len(new_articles),
            articles=articles
        )

        return response

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"检查失败: {str(e)}")

@app.post("/api/rss/refresh", response_model=RSSCheckResponse)
async def refresh_articles():
    """
    强制刷新（可选）
    清除缓存后重新检查
    """
    # TODO: 实现清除缓存逻辑
    return await check_new_articles()
```

### 步骤5: 创建Dockerfile

**backend/rss_notice_service/Dockerfile**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制代码
COPY . .

# 暴露端口
EXPOSE 8020

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8020/health || exit 1

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8020"]
```

**backend/rss_notice_service/requirements.txt**
```txt
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
feedparser>=6.0.10
pydantic>=2.5.0
requests>=2.31.0
python-dotenv>=1.0.0
```

**backend/rss_notice_service/.env**
```env
RSS_URL=http://rss.jintiankansha.me/rss/GM4DMMJYHB6DQNLFMRRWCOBRGZSGKNJSMFSWKMZSG4ZDENRQGZQWIYZRGVSTQYTCHAYGMZRVHEYQ====
DB_PATH=/app/data/rss_notice.db
LOG_LEVEL=INFO
```

### 步骤6: 创建docker-compose.yml

**docker/docker-compose.yml**
```yaml
version: '3.8'

services:
  rss-notice-service:
    build:
      context: ../backend/rss_notice_service
      dockerfile: Dockerfile
    container_name: rss-notice-service
    ports:
      - "8020:8020"
    environment:
      - RSS_URL=${RSS_URL}
      - DB_PATH=${DB_PATH:-/app/data/rss_notice.db}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./data:/app/data  # 持久化数据目录
    networks:
      - api-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8020/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

networks:
  api-network:
    name: api-gateway_api-network
    external: true
```

### 步骤7: API Gateway配置

在API Gateway项目的 `config/services.yaml` 中添加：

```yaml
services:
  # 现有服务...

  # RSS通知服务
  rss_notice:
    url: http://rss-notice-service:8020
    enabled: true
    health_path: /health
    routes:
      - path: /api/rss-notice/check
        method: GET
        backend_path: /api/rss/check

      - path: /api/rss-notice/refresh
        method: POST
        backend_path: /api/rss/refresh
```

## n8n集成流程

### 工作流设计

1. **定时触发器**（Cron）
   - 设置为每天 2:45 执行
   - Cron表达式: `45 2 * * *`

2. **HTTP Request节点**
   - Method: GET
   - URL: `http://api-gateway:8010/api/rss-notice/check`
   - 或者直接: `http://rss-notice-service:8020/api/rss/check`

3. **判断节点**（IF）
   - 检查 `new_count > 0`
   - 如果有新文章，继续；否则结束

4. **钉钉节点**
   - 解析JSON数据
   - 格式化消息
   - 发送到钉钉Webhook

### n8n示例配置

```json
{
  "nodes": [
    {
      "name": "定时触发",
      "type": "cron",
      "parameters": {
        "cronExpression": "45 2 * * *"
      }
    },
    {
      "name": "调用RSS服务",
      "type": "httpRequest",
      "parameters": {
        "method": "GET",
        "url": "http://api-gateway:8010/api/rss-notice/check"
      }
    },
    {
      "name": "判断新文章",
      "type": "if",
      "parameters": {
        "condition": "{{$json.new_count > 0}}"
      }
    },
    {
      "name": "发送钉钉",
      "type": "webhook",
      "parameters": {
        "url": "钉钉Webhook地址",
        "message": "检测到 {{new_count}} 篇新文章：\n{{#each articles}}\n- {{title}}\n{{link}}\n{{/each}}"
      }
    }
  ]
}
```

## 部署流程

### 1. 创建Docker网络（如果不存在）
```bash
docker network create api-gateway_api-network
```

### 2. 构建并启动服务
```bash
cd rss-notice/docker
docker-compose up -d --build
```

### 3. 验证服务
```bash
# 检查容器状态
docker ps | grep rss-notice

# 检查健康状态
curl http://localhost:8020/health

# 测试RSS检查接口
curl http://localhost:8020/api/rss/check
```

### 4. 配置API Gateway
```bash
cd /path/to/api-gateway
# 编辑 config/services.yaml 添加配置
docker-compose restart
```

### 5. 验证路由
```bash
# 通过API Gateway访问
curl http://localhost:8010/api/rss-notice/check
```

## 关键文件清单

实现时最关键的文件：
- **backend/rss_notice_service/main.py** - FastAPI应用入口，路由定义
- **backend/rss_notice_service/models.py** - Pydantic数据模型
- **backend/rss_notice_service/storage.py** - SQLite持久化存储
- **backend/rss_notice_service/rss_fetcher.py** - RSS拉取核心逻辑
- **backend/rss_notice_service/Dockerfile** - Docker镜像构建
- **docker/docker-compose.yml** - 容器编排配置

## 架构优势

1. **符合微服务规范**：提供健康检查、标准化日志、容器化部署
2. **API Gateway集成**：统一路由管理，便于扩展
3. **异步调用**：n8n主动调用，而非定时任务，更灵活
4. **持久化存储**：SQLite记录已处理文章，避免重复通知
5. **易于监控**：标准健康检查接口，便于监控系统集成

## 与原方案对比

| 特性 | 原方案（定时任务） | 新方案（FastAPI + API Gateway） |
|------|------------------|--------------------------------|
| 调用方式 | 定时自动执行 | n8n主动调用API |
| 集成方式 | stdout JSON输出 | RESTful API |
| 扩展性 | 单一职责 | 微服务架构 |
| 监控能力 | 无标准接口 | /health端点 |
| 部署方式 | 独立进程 | Docker容器 + API Gateway |
| 灵活性 | 固定时间执行 | n8n灵活控制 |
